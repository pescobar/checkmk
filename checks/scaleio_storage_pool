<<<<<<< HEAD
#!/usr/bin/python
# -*- encoding: utf-8; py-indent-offset: 4 -*-
# +------------------------------------------------------------------+
# |             ____ _               _        __  __ _  __           |
# |            / ___| |__   ___  ___| | __   |  \/  | |/ /           |
# |           | |   | '_ \ / _ \/ __| |/ /   | |\/| | ' /            |
# |           | |___| | | |  __/ (__|   <    | |  | | . \            |
# |            \____|_| |_|\___|\___|_|\_\___|_|  |_|_|\_\           |
# |                                                                  |
# | Copyright Mathias Kettner 2017             mk@mathias-kettner.de |
# +------------------------------------------------------------------+
#
# This file is part of Check_MK.
# The official homepage is at http://mathias-kettner.de/check_mk.
#
# check_mk is free software;  you can redistribute it and/or modify it
# under the  terms of the  GNU General Public License  as published by
# the Free Software Foundation in version 2.  check_mk is  distributed
# in the hope that it will be useful, but WITHOUT ANY WARRANTY;  with-
# out even the implied warranty of  MERCHANTABILITY  or  FITNESS FOR A
# PARTICULAR PURPOSE. See the  GNU General Public License for more de-
# tails. You should have  received  a copy of the  GNU  General Public
# License along with GNU Make; see the file  COPYING.  If  not,  write
# to the Free Software Foundation, Inc., 51 Franklin St,  Fifth Floor,
# Boston, MA 02110-1301 USA.

=======
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Copyright (C) 2019 tribe29 GmbH - License: GNU General Public License v2
# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and
# conditions defined in the file COPYING, which is part of this source code package.

# NOTE: Careful when replacing the *-import below with a more specific import. This can cause
# problems because it might remove variables from the check-context which are necessary for
# resolving legacy discovery results such as [("SUMMARY", "diskstat_default_levels")]. Furthermore,
# it might also remove variables needed for accessing discovery rulesets.
from cmk.base.check_legacy_includes.df import *  # pylint: disable=wildcard-import,unused-wildcard-import
# NOTE: Careful when replacing the *-import below with a more specific import. This can cause
# problems because it might remove variables from the check-context which are necessary for
# resolving legacy discovery results such as [("SUMMARY", "diskstat_default_levels")]. Furthermore,
# it might also remove variables needed for accessing discovery rulesets.
from cmk.base.check_legacy_includes.diskstat import *  # pylint: disable=wildcard-import,unused-wildcard-import
# NOTE: Careful when replacing the *-import below with a more specific import. This can cause
# problems because it might remove variables from the check-context which are necessary for
# resolving legacy discovery results such as [("SUMMARY", "diskstat_default_levels")]. Furthermore,
# it might also remove variables needed for accessing discovery rulesets.
from cmk.base.check_legacy_includes.scaleio import *  # pylint: disable=wildcard-import,unused-wildcard-import
# NOTE: Careful when replacing the *-import below with a more specific import. This can cause
# problems because it might remove variables from the check-context which are necessary for
# resolving legacy discovery results such as [("SUMMARY", "diskstat_default_levels")]. Furthermore,
# it might also remove variables needed for accessing discovery rulesets.
from cmk.base.check_legacy_includes.size_trend import *  # pylint: disable=wildcard-import,unused-wildcard-import
>>>>>>> upstream/master
#<<<scaleio_storage_pool>>>
#STORAGE_POOL 59c7748300000000:
#        ID                                                 59c7748300000000
#        NAME                                               pool01
#        MAX_CAPACITY_IN_KB                                 65.5 TB (67059 GB)
#        UNUSED_CAPACITY_IN_KB                              17.2 TB (17635 GB)
#        FAILED_CAPACITY_IN_KB                              0 Bytes
#        TOTAL_READ_BWC                                     0 IOPS 0 Bytes per-second
#        TOTAL_WRITE_BWC                                    0 IOPS 0 Bytes per-second
#        REBALANCE_READ_BWC                                 0 IOPS 0 Bytes per-second
#        REBALANCE_WRITE_BWC                                0 IOPS 0 Bytes per-second
#


def inventory_scaleio_storage_pool(parsed):
    for entry in parsed:
        yield entry, {}


def check_scaleio_storage_pool(item, params, parsed):
    data = get_scaleio_data(item, parsed)
    if not data:
        return

    # How will the data be represented? It's magic and the only
    # indication is the unit. We need to handle this!
    unit = data["MAX_CAPACITY_IN_KB"][3].strip(")")
    total = convert_scaleio_space(unit, int(data["MAX_CAPACITY_IN_KB"][2].strip("(")))
    free = convert_scaleio_space(unit, int(data["UNUSED_CAPACITY_IN_KB"][2].strip("(")))

    yield df_check_filesystem_list(item, params, [(item, total, free, 0)])

    failed_value = int(data["FAILED_CAPACITY_IN_KB"][0])
    if failed_value > 0:
        failed_unit = data["FAILED_CAPACITY_IN_KB"][1]
        yield 2, "Failed Capacity: %d %s" % (failed_value, failed_unit)


check_info['scaleio_storage_pool'] = {
    'parse_function': lambda info: parse_scaleio(info, "STORAGE_POOL"),
    'inventory_function': inventory_scaleio_storage_pool,
    'check_function': check_scaleio_storage_pool,
    'service_description': 'ScaleIO SP capacity %s',
<<<<<<< HEAD
    'includes': ['scaleio.include', 'size_trend.include', 'df.include', 'diskstat.include'],
=======
>>>>>>> upstream/master
    'has_perfdata': True,
    'group': 'filesystem',
}


def inventory_scaleio_storage_pool_totalrw(parsed):
    for entry in parsed:
        yield entry, {}


def check_scaleio_storage_pool_totalrw(item, params, parsed):
    data = get_scaleio_data(item, parsed)
    if not data:
        return

    yield 0, "Name: %s" % data["NAME"][0]

    read_data = data["TOTAL_READ_BWC"]
    write_data = data["TOTAL_WRITE_BWC"]
    for io_type in list(check_diskstat_dict(item, params, get_disks(item, read_data, write_data))):
        yield io_type


check_info['scaleio_storage_pool.totalrw'] = {
    'inventory_function': inventory_scaleio_storage_pool_totalrw,
    'check_function': check_scaleio_storage_pool_totalrw,
    'service_description': 'ScaleIO SP total IO %s',
    'has_perfdata': True,
    'group': 'diskstat',
}


def inventory_scaleio_storage_pool_rebalancerw(parsed):
    for entry in parsed:
        yield entry, {}


def check_scaleio_storage_pool_rebalancerw(item, params, parsed):
    data = get_scaleio_data(item, parsed)
    if not data:
        return

    yield 0, "Name: %s" % data["NAME"][0]

    read_data = data["REBALANCE_READ_BWC"]
    write_data = data["REBALANCE_WRITE_BWC"]
    for io_type in list(check_diskstat_dict(item, params, get_disks(item, read_data, write_data))):
        yield io_type


check_info['scaleio_storage_pool.rebalancerw'] = {
    'inventory_function': inventory_scaleio_storage_pool_rebalancerw,
    'check_function': check_scaleio_storage_pool_rebalancerw,
    'service_description': 'ScaleIO SP rebalance IO %s',
    'has_perfdata': True,
    'group': 'diskstat',
}
